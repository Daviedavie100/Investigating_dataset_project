{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Investigate a Dataset - [Database_soccer]\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#eda\">Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "### Dataset Description \n",
    "\n",
    "> In this project, I willl be analysing ultimate soccer dataset, which is an open-source dataset in kaggle. The dataset is a one .sql file comprising seven tables, each with different(unique) but interrelated features. First, Country table has 11 European countries. Second, league table has 11 lead championship names. The country and league tables are related by their ID. Third, match table has over 25, 000 matches for different seasons as well as betting odds from upto 10 providers. The match table is also related to the previous tables by country_id. in the rows and 2 columns id and name\n",
    "I have check the shape of table to determine the nummber of rows and columns.\n",
    "\n",
    "\n",
    "### Question(s) for Analysis\n",
    "1. What teams improved the most over the time period? \n",
    "2. Which players had the most penalties? \n",
    "3. Which was the the most preferred leg for penalty-takers in 2016 among the players who scored more than the mean penalties in that year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements for all of the packages to be used.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to create a function that would read csv and load for very dataset to a name variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to load data\n",
    "path='C:/Users/Davie/Desktop/Data/'\n",
    "def load_data(name, table_name):\n",
    "    name=pd.read_csv(path + 'Database_Soccer/'+ table_name) # reads the csv file and stores in the dataframe name\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "displaying few lines of each dataset from the soccer database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1729</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4769</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7809</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10257</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     name\n",
       "0      1  Belgium\n",
       "1   1729  England\n",
       "2   4769   France\n",
       "3   7809  Germany\n",
       "4  10257    Italy"
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country=load_data('country', 'Country.csv')# country data table\n",
    "country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Belgium Jupiler League</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1729</td>\n",
       "      <td>1729</td>\n",
       "      <td>England Premier League</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4769</td>\n",
       "      <td>4769</td>\n",
       "      <td>France Ligue 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7809</td>\n",
       "      <td>7809</td>\n",
       "      <td>Germany 1. Bundesliga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10257</td>\n",
       "      <td>10257</td>\n",
       "      <td>Italy Serie A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  country_id                    name\n",
       "0      1           1  Belgium Jupiler League\n",
       "1   1729        1729  England Premier League\n",
       "2   4769        4769          France Ligue 1\n",
       "3   7809        7809   Germany 1. Bundesliga\n",
       "4  10257       10257           Italy Serie A"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "league=load_data('league', 'League.csv')# league data table\n",
    "league.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the league name above, the league name for Germany is confusing. Germany 1. could mean there are a number of German countries, so it should be change to Germany Bundesliga 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match=load_data('match', 'Match.csv')# match data table\n",
    "match.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing data in match table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player=load_data('player', 'Player.csv')# player data table\n",
    "player.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The birthday contains time at 00:00:00, which could be removed to contain only year, month and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_attr=load_data('player_attr', 'Player_Attributes.csv') # player attributes data table\n",
    "player_attr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time 00:00:00 can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team=load_data('team', 'Team.csv')# team data table\n",
    "team.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column team_fifa_api_id could insignificant because there is already team_api_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_attr=load_data('team_attr', 'Team_Attributes.csv')# team attributes data table\n",
    "team_attr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want again to develop a function that I will be using in inspecting the datasets for missing data, getting descriptive statistics, dimensions, and features' data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function for inspecting the datasets\n",
    "def wrangles (tbl_name):\n",
    "    \n",
    "    inf=tbl_name.info(); # inspecting data types and instances with missing data \n",
    "    dim=tbl_name.shape; # inspecting dimensions of the dataset\n",
    "    desc=tbl_name.describe(); # getting descriptive statistics\n",
    "        \n",
    "    return inf, dim, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country dataset\n",
    "wrangles(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need of getting the mean for ids, since the names are string we can just unique values and counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country.name.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# league data\n",
    "wrangles(league)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need of getting the mean for ids, since the names are string we can just unique values and counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league.name.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match data\n",
    "wrangles(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing data for column home_player_x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the date has been stored as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player data\n",
    "wrangles(player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "birthday column stored as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player attributes data\n",
    "wrangles(player_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dates stored as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team data\n",
    "wrangles(team)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data for team_fifa_api_id, though this might be insignificant since there is already team_api_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team attributes data\n",
    "wrangles(team_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data for buildUpPlayDribbling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Cleaning\n",
    "\n",
    "First, I want to create functions that will help me drop duplicates, merge two datasets, change data type, remove missing rows, drop unnecessary columns, then proceed to to merge the country data to that for league. \n",
    "I will correct the league name for Germany 1. Bundesliga to Germany Bundesliga 1.\n",
    "I will also change the name column for both the country data and league data, and also make the datafrmaes have the same dimensions and finally merge the two dataframes into country_league data using the country id as the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to rename columns in a data frame\n",
    "def col_rename(col_renamed_data, col_old, col_new):\n",
    "    if len(col_old)==2: # checks if there are two columns to be renamed\n",
    "        col_renamed_data.rename(columns={col_old[0]:col_new[0], col_old[1]:col_new[1]}, inplace=True) # renames the two columns in the dataset\n",
    "    else:\n",
    "        col_renamed_data.rename(columns={col_old:col_new}, inplace=True) # renames if there is only one column to be renamed\n",
    "        \n",
    "    return col_renamed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function drop columns\n",
    "def drop_cols(drop_col_data, col_name):\n",
    "    drop_col_data.drop(col_name, axis=1, inplace=True) # removing columns\n",
    "        \n",
    "    return drop_col_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to remove row missing values\n",
    "def remove_row_missing_values(na_data):\n",
    "    na_data.dropna(axis=0, how='any', inplace=True) # removing all rows with missing values\n",
    "        \n",
    "    return na_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to remove duplicate rows\n",
    "def remove_duplicates(dup_data, col):\n",
    "    if col=='':\n",
    "        dup_data.drop_duplicates(inplace=True) # remove all duplicate rows\n",
    "        \n",
    "    else:\n",
    "        dup_data.dropna(subset=[col], inplace=True) # removing rows based on column duplicate values\n",
    "        \n",
    "    return dup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to change date column from string to datetime\n",
    "def changed_type(changed_type_data, col_type):\n",
    "    changed_type_data[col_type]=changed_type_data[col_type].astype('str')  # converting to string\n",
    "    changed_type_data[col_type]=changed_type_data[col_type].str.extract(r'(\\d{4}-\\d{2}-\\d{2})') # extracting the date\n",
    "    changed_type_data[col_type] = pd.to_datetime(changed_type_data[col_type], format='%Y-%m-%d') # converting to datetime\n",
    "\n",
    "    return changed_type_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to filter some columns\n",
    "def filter_col(f_data, col):\n",
    "    df=f_data.filter(col) # filters the columns\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to to merge two data frames using inner because i dont want do keep duplicates\n",
    "def merging_data(data1, data2, on_col):\n",
    "    df=data1.merge(data2, on =on_col, how='inner')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting the league name for Germany 1. Bundesliga\n",
    "league.replace(to_replace='Germany 1. Bundesliga', value='Germany Bundesliga 1', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing both id and name columns for the country data\n",
    "country=col_rename(country, col_old=['name', 'id'], col_new=['country_name', 'country_id']) \n",
    "country "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the name column and id column  for the league data\n",
    "league=col_rename(league, col_old=['name', 'id'], col_new=['league_name', 'league_id']) \n",
    "league"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the two dataframes country and league\n",
    "country_league_info=merging_data(country, league, on_col ='country_id')\n",
    "country_league_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, I want to merge the player data to player attributes data into player_info dataframe.\n",
    "I will use either the player_api_id or player_fifa_api_id as the keys and drop the id columns in both datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of unique values of player_api_id on payer and player attribute data\n",
    "player.player_api_id.nunique()==player_attr.player_api_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of unique values of  player_fifa_api_id on player and player attribute data\n",
    "player.player_fifa_api_id.nunique()==player_attr.player_fifa_api_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of unique values of the player_fifa_api_id are not the same in both dataframes, I will just use both of them as the key because both the ids might be important in merging this data with another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping id column from player dataframe\n",
    "drop_cols(player, col_name='id')\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping id column from player_attr dataframe\n",
    "drop_cols(player_attr, col_name='id')\n",
    "player_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicates for player attribute data\n",
    "remove_duplicates(player_attr, col='')\n",
    "#layer_attr.sort_values(['player_api_id', 'date']) # sorting the players by id and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the two dataframes on player_api_id and player_fifa_api_id using inner join because i dont want the unmatched rows\n",
    "player_info=merging_data(player, player_attr, on_col =['player_api_id', 'player_fifa_api_id'])\n",
    "player_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now want to examine the player_info dataframe, check for missing values, dimensions of each column, data types of each column as well as duplcate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_info.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above uotput, there are several missing values, the data type for birthday and date are all strings. I have also noted that attacking_work_rate has the least number of rows hence maximum number of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the uniques for the coulmn attacking_work_rate\n",
    "player_info.attacking_work_rate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the uniques for the coulmn attacking_work_rate\n",
    "player_info.defensive_work_rate.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output in above two cells, no information has been provided from the data description about the meaning of None, norm, y, stoc, le, ornal, es, tocky, ean o, and the numbers 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9 . Howerver, from inspection, I realize that there is some association in that all the numbers 0-9 and o on the defensive_work_rate relates to None  on the attacking_work_rate. Also, the following  pairs also relate: norm-ornal, y-es, stoc-tocky, le-ean. These could be change or transformed if additional information is provided or simply be dropped from the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacking_none=player_info.query('attacking_work_rate==\"None\"')\n",
    "attacking_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing length of numbers 0-9 and o in the defensive_work_rate relates to None in the attacking_work_rate\n",
    "\n",
    "attacking_none.attacking_work_rate.value_counts()==attacking_none.defensive_work_rate.value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- None: This likely means no specific attacking work rate is assigned. Treat it as a default or neutral value - null/medium.\n",
    "- le: This could be an abbreviation for \"less effort\" or something similar. map it to a \"Low\" attacking work rate.\n",
    "- norm: This probably stands for \"normal.map it to a \"Medium\" attacking work rate.\n",
    "- stoc: This might be short for \"stock\" or default settings. map it to \"Medium.\"\n",
    "- y: This is unclear, but it might be a placeholder or a specific setting in a custom game mode. Remove\n",
    "- I want to drop all rows with nan and duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacking_work_rate_mapping={\n",
    "    'None': np.NAN,\n",
    "    'le': 'low',\n",
    "    'norm': 'medium',\n",
    "    'stoc': 'medium',\n",
    "    'y': np.NAN\n",
    "}\n",
    "player_info['attacking_work_rate']=player_info['attacking_work_rate'].replace(attacking_work_rate_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_info['attacking_work_rate'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5, 1, 7, 2, 8, 4, 0, 3, 6, 9: mapping based on the context or frequency of these values.\n",
    "- ean: Possibly a typo for \"mean\" or \"lean.\" map it to \"Medium\" or \"Low.\"\n",
    "- o: Could be a typo or placeholder. Remove\n",
    "- ormal: Likely a typo for \"normal,\" which you can map to \"Medium.\"\n",
    "- tocky: Possibly a typo for \"stocky,\" which might imply a strong defensive presence. map it to \"High.\"\n",
    "- es: Could be a typo for \"yes\" or another term. Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "defensive_work_rate_mapping = {\n",
    "    '0': 'low',\n",
    "    '1': 'low',\n",
    "    '2': 'low',\n",
    "    '3': 'low',\n",
    "    '4': 'medium',\n",
    "    '5': 'medium',\n",
    "    '6': 'medium',\n",
    "    '7': 'high',\n",
    "    '8': 'high',\n",
    "    '9': 'high',\n",
    "    'ean':'low',\n",
    "    'ormal': 'medium',\n",
    "    'tocky': 'high',\n",
    "    'o':np.nan,\n",
    "    'es':np.nan\n",
    "}\n",
    "player_info['defensive_work_rate']=player_info['defensive_work_rate'].replace(defensive_work_rate_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_info['defensive_work_rate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all rows with missing data\n",
    "remove_row_missing_values(player_info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicate rows\n",
    "remove_duplicates(player_info, col='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_info.attacking_work_rate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_info.defensive_work_rate.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to change the data types for birthday and date from string to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting birthday column into datetime\n",
    "changed_type(player_info, col_type='birthday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting date column into datetime\n",
    "changed_type(player_info, col_type='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, I want merge team data to team attributes data into into team info dataframe, check data types, missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of unique values of team_api_id in team and team attribute data\n",
    "team.team_api_id.nunique()==team_attr.team_api_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of unique values of team_fifa_api_id in team and team attribute data\n",
    "team.team_fifa_api_id.nunique()==team_attr.team_fifa_api_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these outputs, it is clear that neither the team_api_id nor the team_fifa_api_id matches in the two datasets. I will therefore merge them on both the team_api_id and team_fifa_api_id as the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the id for team dataframe\n",
    "drop_cols(team, col_name='id').drop_duplicates(subset='team_api_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team.team_long_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to correct the following team names: '1. FC Köln', '1. FC Nürnberg', '1. FSV Mainz 05','1. FC Kaiserslautern'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting some team names\n",
    "team.team_long_name.replace(to_replace=['1. FC Köln', '1. FC Nürnberg', '1. FSV Mainz 05','1. FC Kaiserslautern'], \n",
    "                            value=['FC Köln', 'FC Nürnberg', 'FSV Mainz 05','FC Kaiserslautern'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_attr.dropna(how='any').drop_duplicates(subset='team_api_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the id for team attributes data\n",
    "drop_cols(team_attr, col_name='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging team to the team attribute\n",
    "team_info=team.merge(team_attr, on =['team_api_id', 'team_fifa_api_id'], how='inner') #\n",
    "team_info['team_fifa_api_id']=team_info['team_fifa_api_id'].astype(int)\n",
    "team_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will populate the NaN in the buildUpPlayDribbling column with the mean of the column. And finally drop duplcates in the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the mean of buildUpPlayDribbling column\n",
    "#mean=team_info.buildUpPlayDribbling.mean()\n",
    "\n",
    "# filling the NaNs in the buildUpPlayDribbling by the mean\n",
    "#team_info['buildUpPlayDribbling']=team_info['buildUpPlayDribbling'].fillna(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to datetime\n",
    "changed_type(team_info, col_type='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the duplicate rows in the final team info merged data\n",
    "team_info=team_info.copy()\n",
    "drop_cols(team_info, col_name=['team_fifa_api_id',])\n",
    "team_info.drop_duplicates(subset='team_api_id')\n",
    "team_info.dropna(how='any', inplace=True)\n",
    "#remove_duplicates(team_info, col='')\n",
    "team_info.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I to examine and merge match data, country_league, and team data to form march info dataframe. I will check for duplicates, missing values and correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of league_id unique values in the match and country_league_info dataframes\n",
    "match.league_id.nunique()==country_league_info.league_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of country_id unique values in the match and country_league_info dataframes\n",
    "match.country_id.nunique()==country_league_info.country_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will merge match and country_league_info dataframes on league_id and country_id, so that I retain all the info about ids. I want to drop all the columns containing odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in match.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to remove all the columns with CAPITAL LETTERS, odds columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to datetime for the match data\n",
    "changed_type(match, col_type='date').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the duplicate rows from match data\n",
    "remove_duplicates(match, col='').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the columns containg odds and the match id\n",
    "odd_cols = list(filter(lambda x: x.isupper(), match.columns))\n",
    "drop_cols(match, col_name=odd_cols)\n",
    "drop_cols(match, col_name='id')\n",
    "match.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the contents of some columns\n",
    "```match.goal.value_counts() # goal```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two cells, I realised that the coulmns goal, shoton, shotoff, foulcommit, card, cross, corner and possession contains information related to the web page but not realistic data.Checking through the nested infomation, I can't really make sense out of it since even the website link to the discription is not loading. Instead of deleting the columns with such issues, I will instead drop the columns containing unprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match.columns\n",
    "match_info=filter_col(match, col=['country_id', 'league_id', 'season', 'stage', 'date', 'match_api_id', 'home_team_api_id', 'away_team_api_id', 'home_team_goal', 'away_team_goal'])\n",
    "\n",
    "match_info.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_info['results'] = np.where(\n",
    "    match_info['home_team_goal'] == match_info['away_team_goal'], 'draw',\n",
    "    np.where(\n",
    "        match_info['home_team_goal'] > match_info['away_team_goal'], 'home win', 'away win'\n",
    "    )\n",
    ")\n",
    "\n",
    "match_info.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the data\n",
    "match_info=merging_data(country_league_info, match_info, on_col =['country_id', 'league_id'])\n",
    "match_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_info=match_info.drop(columns=['country_id', 'league_id'])\n",
    "match_info.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt home and away teams id_vars are columns not melted\n",
    "# creating columns not melted\n",
    "unmelted_columns= [x for x in match_info.columns if x not in ['home_team_api_id', 'away_team_api_id']]\n",
    "\n",
    "# melting home and away teams api ids\n",
    "melted_match=match_info.melt(id_vars=unmelted_columns, var_name='Location', value_name='Team')\n",
    "melted_match.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up or changing the location values\n",
    "melted_match['Location']=melted_match['Location'].replace({'home_team_api_id':'home', 'away_team_api_id':'away'})\n",
    "melted_df=melted_match.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging the team_info to the melted_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = ['team_long_name', 'team_short_name', 'date']\n",
    "team_info = team_info.drop(columns=exclude_columns).drop_duplicates(subset='team_api_id')\n",
    "\n",
    "team_info.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_info.rename(columns={'team_api_id':'Team'}, inplace=True)\n",
    "team_s=team_info.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "melted_match=pd.merge(melted_df, team_s, on ='Team', how='left')\n",
    "#melted_match.drop_duplicates(subset='match_api_id' , inplace=True)\n",
    "melted_match.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating team dictionary with team api ids as the key and a longname as the value\n",
    "team_dict=team.set_index('team_api_id')['team_long_name'].to_dict()\n",
    "team_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up team i.e. using team dictionary to replace team api ids\n",
    "melted_match['Team']=melted_match['Team'].map(team_dict)\n",
    "melted_match.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating goals column\n",
    "melted_match['goals']=np.where(melted_match['Location']=='home',melted_match['home_team_goal'], melted_match['away_team_goal'])\n",
    "melted_match.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_match['pts'] = np.where(\n",
    "    melted_match['results'] == 'draw', 1, \n",
    "    np.where(\n",
    "        (melted_match['results'] == 'away win') & (melted_match['Location'] == 'home'), 0, \n",
    "        np.where(\n",
    "            (melted_match['results'] == 'home win') & (melted_match['Location'] == 'away'), 0, 3\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "melted_match.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_match.sort_values(by=['match_api_id', 'season'])\n",
    "melted_match.drop_duplicates() #subset='match_api_id', inplace=True\n",
    "melted_match.dropna(how='any')\n",
    "melted_match.sort_values(by='match_api_id', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goals For for the home team\n",
    "melted_match['GF'] = np.where(\n",
    "    # Case 1\n",
    "    (melted_match['Location'] == 'home') & (melted_match['results'] == 'home win'),  \n",
    "    melted_match['goals'],  \n",
    "    np.where(\n",
    "        # Case 2\n",
    "        (melted_match['Location'] == 'home') & (melted_match['results'] == 'away win'),  \n",
    "        melted_match['goals'],  \n",
    "\n",
    "        np.where(\n",
    "            # Case 3\n",
    "            (melted_match['Location'] == 'away') & (melted_match['results'] == 'home win'),  \n",
    "            melted_match['goals'],  \n",
    "\n",
    "            np.where(\n",
    "                # Case 4\n",
    "                (melted_match['Location'] == 'home') & (melted_match['results'] == 'draw'),  \n",
    "                melted_match['goals'],  \n",
    "\n",
    "                np.where(\n",
    "                    # Case 5\n",
    "                    (melted_match['Location'] == 'away') & (melted_match['results'] == 'draw'),  \n",
    "                    melted_match['goals'],  \n",
    "\n",
    "                    np.where(\n",
    "                        # Case 6\n",
    "                        (melted_match['Location'] == 'away') & (melted_match['results'] == 'away win'),  \n",
    "                        melted_match['goals'], \n",
    "\n",
    "                        0  # If none of the conditions are met, GF is 0 for the home team\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "melted_match.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goals Against for the home team\n",
    "melted_match['GA'] = np.where(\n",
    "    # Case 1\n",
    "    (melted_match['Location'] == 'home') & (melted_match['results'] == 'home win'),  \n",
    "    melted_match['away_team_goal'], \n",
    "\n",
    "    np.where(\n",
    "        # Case 2 \n",
    "        (melted_match['Location'] == 'away') & (melted_match['results'] == 'home win'),  \n",
    "        melted_match['home_team_goal'],  \n",
    "        np.where(\n",
    "            # Case 3\n",
    "            (melted_match['Location'] == 'home') & (melted_match['results'] == 'draw'),  \n",
    "            melted_match['away_team_goal'],  \n",
    "            np.where(\n",
    "                # Case 4\n",
    "                (melted_match['Location'] == 'away') & (melted_match['results'] == 'draw'),  \n",
    "                melted_match['home_team_goal'], \n",
    "\n",
    "                np.where(\n",
    "                    # Case 5\n",
    "                    (melted_match['Location'] == 'away') & (melted_match['results'] == 'away win'),  \n",
    "                    melted_match['home_team_goal'],  \n",
    "\n",
    "                    np.where(\n",
    "                        # Case 6\n",
    "                        (melted_match['Location'] == 'away') & (melted_match['results'] == 'home win'),  \n",
    "                        melted_match['home_team_goal'],  \n",
    "\n",
    "                        np.where(\n",
    "                        # Case 7\n",
    "                        (melted_match['Location'] == 'home') & (melted_match['results'] == 'away win'),  \n",
    "                        melted_match['away_team_goal'],  \n",
    "\n",
    "                        0  # Default case (if none of the above conditions are met\n",
    "                        )\n",
    "\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "melted_match.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Goal Difference\n",
    "melted_match['GD'] = melted_match['GF'] - melted_match['GA']\n",
    "melted_match.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a function to plot different visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual(data, data2, visual_type):\n",
    "    if visual_type=='barh':\n",
    "        data.plot(kind='barh', rot=0, width=0.7, alpha=0.8, color='grey', figsize=[8,20] ) # i want to creat horizontal bars\n",
    "            \n",
    "    elif visual_type=='hist':\n",
    "        fig,vis=plt.subplots(figsize=[10,8])\n",
    "        vis.hist(data, alpha=0.8, bins=40) # creating a histogram\n",
    "        #plt.grid(axis='y', alpha=0.6) # grid\n",
    "            \n",
    "    elif visual_type=='boxplot':\n",
    "        fig,vis=plt.subplots(figsize=[8,4])\n",
    "        vis.boxplot(data, vert=0) # creating a box plot\n",
    "        #plt.grid(axis='x', alpha=0.6)\n",
    "                     \n",
    "    else:\n",
    "        fig, vis=plt.subplots(figsize=[10,8])\n",
    "        plt.scatter(x=data, y=data2, alpha=0.8, color='blue') # creating scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the distribution of goals in the seasons\n",
    "goals_08_to_16=melted_match.groupby(['season', 'Team'])['goals'].sum() \n",
    "# plot histogram\n",
    "plot_visual(data=goals_08_to_16, data2='', visual_type='hist')\n",
    "plt.title('HISTOGRAM')\n",
    "plt.xlabel('bins')\n",
    "plt.ylabel('No of goals scored in the season');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph shows that the distribution of goals is right screwed. Further investigation can be shown on the boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot box plot\n",
    "plot_visual(data=goals_08_to_16, data2='', visual_type='boxplot')\n",
    "plt.title('SEASON 2008/2009 - 2015/2016 BOXPLOT')\n",
    "plt.xlabel('No of goals scored');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is rght skewed but with severa outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question 1 What is the league table for the 4 major leagues in europe during 2015/2016 season? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_match['league_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the data\n",
    "columns_order = ['Pos', 'season', 'league_name', 'Club', 'MP', 'W', 'D', 'L', 'Pts', 'GF', 'GA', 'GD', 'avg_goals']\n",
    "filtered_columns= ['Pos', 'Club', 'MP', 'W', 'D', 'L', 'Pts', 'GF', 'GA', 'GD', 'avg_goals']\n",
    "\n",
    "def league_table(league):\n",
    "    # Filter the data for the given league and season\n",
    "    df_15_16 = (\n",
    "        melted_match\n",
    "        .query('season == \"2015/2016\" and league_name == @league')  \n",
    "        .groupby(['season', 'league_name', 'Team'], as_index=False)\n",
    "        .agg({\n",
    "            'match_api_id': 'count',  # Total matches played\n",
    "            'pts': [\n",
    "                lambda x: (x == 3).sum(),  # Wins\n",
    "                lambda x: (x == 1).sum(),  # Draws\n",
    "                lambda x: (x == 0).sum(),  # Losses\n",
    "                'sum'  # Total points\n",
    "            ],\n",
    "            'GF': 'sum',\n",
    "            'GA': 'sum',\n",
    "            'GD': 'sum',\n",
    "            'goals': 'mean',  # Average goals\n",
    "        })\n",
    "    )\n",
    "\n",
    "    # Flatten the column names\n",
    "    df_15_16.columns = [\n",
    "        'season', 'league_name', 'Club', 'MP', \n",
    "        'W', 'D', 'L', 'Pts', 'GF', 'GA', 'GD', 'avg_goals'\n",
    "    ]\n",
    "\n",
    "    # Sort the result by Pts and GD\n",
    "    df_15_16 = df_15_16.sort_values(by=['Pts', 'GD'], ascending=[False, False])\n",
    "\n",
    "    # Add a Rank column\n",
    "    df_15_16['Pos'] = df_15_16.reset_index().index + 1\n",
    "    # Reorder columns \n",
    "    df_15_16 = df_15_16[columns_order].reset_index()\n",
    "    # filter columns\n",
    "    df_15_16  = df_15_16[filtered_columns]\n",
    "\n",
    "\n",
    "    return df_15_16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) England Premier League Table for 2015/2016 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_table(league=\"England Premier League\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) France Ligue 1 Table for 2015/2016 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_table(league=\"France Ligue 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Spain LIGA BBVA Table for 2015/2016 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_table(league=\"Spain LIGA BBVA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Italy Serie A Table for 2015/2016 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_table(league=\"Italy Serie A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving for Google Looker Studio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_looker = (\n",
    "    melted_match\n",
    "    #.query('season == \"2009/2010\" and league_name == \"England Premier League\"')  # Filter for the specified season and league\n",
    "    .groupby(['season', 'league_name', 'Team'], as_index=False)\n",
    "    .agg({\n",
    "        'match_api_id': 'count',  # Total matches played\n",
    "        'pts': [\n",
    "            lambda x: (x == 3).sum(),  # Wins\n",
    "            lambda x: (x == 1).sum(),  # Draws\n",
    "            lambda x: (x == 0).sum(),  # Losses\n",
    "            'sum'  # Total points\n",
    "        ],\n",
    "        'GF': 'sum',\n",
    "        'GA': 'sum',\n",
    "        'GD': 'sum',\n",
    "        'goals': 'mean',  # Average goals\n",
    "    })\n",
    ")\n",
    "\n",
    "# Flatten the column names\n",
    "df_google_looker.columns = [\n",
    "    'season', 'league_name', 'Club', 'MP', \n",
    "    'W', 'D', 'L', 'Pts', 'GF', 'GA', 'GD', 'avg_goals'\n",
    "]\n",
    "\n",
    "# Sort the result by total_pts\n",
    "df_google_looker = df_google_looker.sort_values(by=['Pts', 'GD'], ascending=[False, False])\n",
    "\n",
    "df_google_looker.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "df_google_looker.to_csv('league_table_for_lookerStudio.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question 2 Which are the top 3 teams for each league in 2015/2016 season? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing\n",
    "top_3_teams = (\n",
    "    melted_match\n",
    "    .query('season==\"2015/2016\"')  \n",
    "    .groupby(['season', 'league_name', 'Team'], as_index=False)['pts'] \n",
    "    .sum()\n",
    "    .sort_values(by=['season', 'league_name', 'pts'], ascending=[True, True, False])\n",
    "    .groupby(['season', 'league_name'], as_index=False)\n",
    "    .head(3)\n",
    ")\n",
    "\n",
    "top_3_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7))\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(data=top_3_teams, x='pts', y='Team', hue='league_name', dodge=False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Top 3 Teams in Each League (2015/2016 Season)', fontsize=16)\n",
    "plt.xlabel('Points', fontsize=12)\n",
    "plt.ylabel('Teams', fontsize=12)\n",
    "\n",
    "# Add horizontal lines to separate leagues\n",
    "league_boundaries = top_3_teams.groupby('league_name')['Team'].count().cumsum().values[:-1]\n",
    "for boundary in league_boundaries:\n",
    "    plt.axhline(y=boundary - 0.5, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title='League', fontsize=10, title_fontsize=10, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question 3 What teams improved the most over the time period? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use Year-Over-Year Improvements (YoY)\n",
    "- The teams played different number of matches. We normalize Points Based on Total Matches Played\n",
    "- Then divide the points by the total matches played in each season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total points for each team per season\n",
    "match_imp08_16=melted_match.query(\n",
    "    'season in [\"2008/2009\", \"2009/2010\", \"2010/2011\", \"2011/2012\", \"2012/2013\", \"2013/2014\", \"2014/2015\", \"2015/2016\"]'\n",
    "    ).groupby(\n",
    "        ['season', 'Team'])['pts'].sum().unstack('season')\n",
    "\n",
    "match_imp08_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total matches played for each team per season\n",
    "match_impp08_16=melted_match.query(\n",
    "    'season in [\"2008/2009\", \"2009/2010\", \"2010/2011\", \"2011/2012\", \"2012/2013\", \"2013/2014\", \"2014/2015\", \"2015/2016\"]'\n",
    "    ).groupby(\n",
    "        ['season', 'Team'])['match_api_id'].count().unstack('season')\n",
    "\n",
    "match_impp08_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide points by number of matches played\n",
    "df_normalized=match_imp08_16/match_impp08_16\n",
    "df_normalized.dropna(how='any', inplace=True)\n",
    "df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate YoY improvements\n",
    "\n",
    "'''# Difference between consecutive seasons\n",
    "yoy_improvements = df_normalized.diff(axis=1)  \n",
    "\n",
    "# Add a column: total YoY improvement\n",
    "yoy_improvements['Total_YoY_Improvement'] = yoy_improvements.sum(axis=1)\n",
    "\n",
    "# Team with the maximum YoY improvement\n",
    "most_consistent_team = yoy_improvements['Total_YoY_Improvement'].idxmax()\n",
    "max_yoy_improvement = yoy_improvements.loc[most_consistent_team, 'Total_YoY_Improvement']\n",
    "\n",
    "# Result\n",
    "print(f\"The most consistent improver is {most_consistent_team} with a total YoY improvement of {max_yoy_improvement} points.\");'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate YoY improvements\n",
    "df_normalized['Total_YoY_Improvement']=(\n",
    "    (df_normalized['2009/2010'] - df_normalized['2008/2009']) +\n",
    "    (df_normalized['2010/2011'] - df_normalized['2009/2010']) +\n",
    "    (df_normalized['2011/2012'] - df_normalized['2010/2011']) +\n",
    "    (df_normalized['2012/2013'] - df_normalized['2011/2012']) +\n",
    "    (df_normalized['2013/2014'] - df_normalized['2012/2013']) +\n",
    "    (df_normalized['2014/2015'] - df_normalized['2013/2014']) +\n",
    "    (df_normalized['2015/2016'] - df_normalized['2014/2015'])\n",
    "    )\n",
    "\n",
    "df_normalized[df_normalized['Total_YoY_Improvement']>0].reset_index().sort_values(by='Total_YoY_Improvement', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improve\n",
    "df0=df_normalized[df_normalized['Total_YoY_Improvement']>0].reset_index().sort_values(by='Total_YoY_Improvement', ascending=False)\n",
    "# drop\n",
    "df00=df_normalized[df_normalized['Total_YoY_Improvement']<0].reset_index().sort_values(by='Total_YoY_Improvement', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# chart 1 improve\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, position 1\n",
    "sns.barplot(data=df0, y='Team', x='Total_YoY_Improvement',dodge=False, palette='viridis')\n",
    "plt.title('Most Improved Teams Accross Seasons', fontsize=16)\n",
    "plt.xlabel('Total_YoY_Improvement', fontsize=12)\n",
    "plt.ylabel('Teams', fontsize=12)\n",
    "\n",
    "# chart 2 drop\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, position 2\n",
    "sns.barplot(data=df00, y='Team', x='Total_YoY_Improvement',dodge=False, palette='viridis_r')\n",
    "plt.title('Teams with Most Decline Across Seasons', fontsize=16)\n",
    "plt.xlabel('Total_YoY_Improvement', fontsize=12)\n",
    "plt.ylabel('') \n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The most consistent improver is Napoli with a total YoY improvement of 0.9473684210526316 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight 1: Team Playing Style Analysis\n",
    "- Identify unique playing styles for teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing\n",
    "\n",
    "# Team attributes against goals and points obtained\n",
    "class_list =[]\n",
    "for i in melted_match.columns:\n",
    "    if 'Class' not in i:\n",
    "        class_list.append(i)\n",
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_list=['country_name', 'stage', 'date', 'match_api_id', 'home_team_goal', 'away_team_goal', 'results', 'Location']\n",
    "req_columns=[\n",
    " 'season',\n",
    " 'league_name',\n",
    " 'Team',\n",
    " 'buildUpPlaySpeed',\n",
    " 'buildUpPlayDribbling',\n",
    " 'buildUpPlayPassing',\n",
    " 'chanceCreationPassing',\n",
    " 'chanceCreationCrossing',\n",
    " 'chanceCreationShooting',\n",
    " 'defencePressure',\n",
    " 'defenceAggression',\n",
    " 'defenceTeamWidth',\n",
    " 'goals',\n",
    " 'pts',\n",
    " 'GF',\n",
    " 'GA',\n",
    " 'GD']\n",
    "num_columns=[ 'buildUpPlaySpeed',\n",
    " 'buildUpPlayDribbling',\n",
    " 'buildUpPlayPassing',\n",
    " 'chanceCreationPassing',\n",
    " 'chanceCreationCrossing',\n",
    " 'chanceCreationShooting',\n",
    " 'defencePressure',\n",
    " 'defenceAggression',\n",
    " 'defenceTeamWidth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_match[req_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_class = (\n",
    "    melted_match.groupby(['season', 'league_name', 'Team'] + num_columns, as_index=False) \n",
    "    .agg({\n",
    "        'match_api_id': 'count',  # Total matches played\n",
    "        'pts': [\n",
    "            lambda x: (x == 3).sum(),  # Wins\n",
    "            lambda x: (x == 1).sum(),  # Draws\n",
    "            lambda x: (x == 0).sum(),  # Losses\n",
    "            'sum'  # Total points\n",
    "        ],\n",
    "        'GF': 'sum',\n",
    "        'GA': 'sum',\n",
    "        'GD': 'sum',\n",
    "        'goals': 'mean',  # Average goals\n",
    "    })\n",
    ")\n",
    "\n",
    "# Flatten the column names\n",
    "melted_class.columns = [\n",
    "    'season', 'league_name', 'Team'] + num_columns + ['MP', \n",
    "    'W', 'D', 'L', 'Pts', 'GF', 'GA', 'GD', 'Avg_Goals']\n",
    "\n",
    "# Sort the result by total_pts\n",
    "melted_class = melted_class.sort_values(by=['season', 'league_name', 'Pts'], ascending=[True, True, False])\n",
    "\n",
    "melted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the numeric columns to ensure equal weighting during clustering.\n",
    "- Use the relevant columns for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns for analysis\n",
    "numeric_columns = [\n",
    "    'buildUpPlaySpeed', 'buildUpPlayDribbling', 'buildUpPlayPassing', \n",
    "    'chanceCreationPassing', 'chanceCreationCrossing', 'chanceCreationShooting',\n",
    "    'defencePressure', 'defenceAggression', 'defenceTeamWidth'\n",
    "]\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "melted_class_normalized = melted_class.copy()\n",
    "melted_class_normalized[numeric_columns] = scaler.fit_transform(melted_class[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of clusters\n",
    "num_clusters = 4\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "melted_class_normalized['Cluster'] = kmeans.fit_predict(melted_class_normalized[numeric_columns])\n",
    "\n",
    "# Add cluster labels to the original data\n",
    "melted_class['Cluster'] = melted_class_normalized['Cluster']\n",
    "\n",
    "# Display the final dataframe\n",
    "melted_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Clusters\n",
    "- Calculate the average values of numeric columns for each cluster to interpret playing styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_analysis = (\n",
    "    melted_class\n",
    "    .groupby('Cluster')[numeric_columns]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "cluster_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cluster labels\n",
    "cluster_labels = {\n",
    "    0: 'Balanced',\n",
    "    1: 'Balanced-to-Offensive',\n",
    "    2: 'Defensive',\n",
    "    3: 'Offensive'  \n",
    "}\n",
    "\n",
    "# Rename clusters\n",
    "cluster_analysis['Cluster'] = cluster_analysis['Cluster'].map(cluster_labels)\n",
    "cluster_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radar Chart Visualization\n",
    "- Visualize the playing styles for each cluster using radar charts\n",
    "- Offensive Playstyle: High buildUpPlayPassing, chanceCreationPassing, chanceCreationShooting. Low defencePressure and defenceAggression.\n",
    "- Defensive Playstyle: High defencePressure, defenceAggression, and defenceTeamWidth. Low offensive attributes.\n",
    "- Balanced Playstyle: Moderate values across both offensive and defensive attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes\n",
    "attributes = [\n",
    "    'buildUpPlaySpeed', 'buildUpPlayDribbling', 'buildUpPlayPassing',\n",
    "    'chanceCreationPassing', 'chanceCreationCrossing', 'chanceCreationShooting',\n",
    "    'defencePressure', 'defenceAggression', 'defenceTeamWidth'\n",
    "]\n",
    "\n",
    "# Angles for radar chart\n",
    "angles = np.linspace(0, 2 * np.pi, len(attributes), endpoint=False).tolist()\n",
    "angles += angles[:1]  # Close the circle\n",
    "\n",
    "# Iterate through each cluster\n",
    "for cluster_label in cluster_analysis['Cluster'].unique():\n",
    "    # Filter data for the current cluster\n",
    "    cluster_data = cluster_analysis[cluster_analysis['Cluster'] == cluster_label]\n",
    "    \n",
    "    # Extract values\n",
    "    cluster_values = cluster_data[attributes].values[0].tolist()\n",
    "    cluster_values += cluster_values[:1]\n",
    "\n",
    "    # Plot \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.polar(angles, cluster_values, marker='o', color='blue', label=cluster_label)\n",
    "    plt.fill(angles, cluster_values, color='blue', alpha=0.25)\n",
    "    \n",
    "    # Add labels\n",
    "    plt.thetagrids(np.degrees(angles[:-1]), labels=attributes, fontsize=10)\n",
    "    plt.title(f'{cluster_label} Cluster Playing Style', size=14, color='blue', pad=20)\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1.2))\n",
    "\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Comparing Clusters with Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge clusters with performance metrics\n",
    "performance_analysis = melted_class[['Team', 'Cluster', 'Pts', 'GF', 'GA', 'GD']]\n",
    "\n",
    "# Group by cluster and analyze average performance\n",
    "performance_by_cluster = (\n",
    "    performance_analysis\n",
    "    .groupby('Cluster')[['Pts', 'GF', 'GA', 'GD']]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "performance_by_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cluster labels\n",
    "cluster_labels = {\n",
    "    0: 'Offensive',\n",
    "    1: 'Balanced',\n",
    "    2: 'Defensive-to-Balanced',\n",
    "    3: 'Weak Defensive'  \n",
    "}\n",
    "\n",
    "# Rename the clusters\n",
    "performance_by_cluster['Cluster'] = performance_by_cluster['Cluster'].map(cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize performance differences using bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.barplot(data=performance_by_cluster.melt(id_vars='Cluster'), x='Cluster', y='value', hue='variable')\n",
    "\n",
    "plt.title('Performance Metrics by Cluster', fontsize=16)\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Average Value')\n",
    "plt.legend(title='Metric')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "- Radar charts helps to identify the offensive, defensive, or balanced styles of each cluster.\n",
    "- From the performance metrics, offensive and balanced styles are the most effective playing styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight 2: Analysisng the correlation of Attributes with Performance\n",
    "- Determine how specific attributes impact performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns for analysis\n",
    "numeric_columns = ['buildUpPlaySpeed', 'buildUpPlayDribbling', 'buildUpPlayPassing', \n",
    "                   'chanceCreationPassing', 'chanceCreationCrossing', 'chanceCreationShooting', \n",
    "                   'defencePressure', 'defenceAggression', 'defenceTeamWidth', \n",
    "                   'GF', 'GA', 'GD', 'pts', 'goals']\n",
    "\n",
    "# Filter relevant columns\n",
    "correlation_data = melted_match[numeric_columns]\n",
    "\n",
    "# Correlation matrix\n",
    "correlation_matrix = correlation_data.corr()\n",
    "correlation_matrix # table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the correlation matrix in a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='cividis_r', cbar=True)\n",
    "plt.title('Correlation Between Class Attributes and Performance Metrics')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the correlation Between Build-Up Play Passing and Goals Scored on a Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=melted_class, x='buildUpPlayPassing', y='GF')\n",
    "\n",
    "plt.title('Correlation Between Build-Up Play Passing and Goals Scored (GF)')\n",
    "plt.xlabel('Build-Up Play Passing')\n",
    "plt.ylabel('Goals Scored (GF)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression for buildUpPlayPassing and GF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = melted_class[['buildUpPlayPassing']]\n",
    "y = melted_class['GF']\n",
    "\n",
    "# Add a constant for the regression\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Display results\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight 3: League-Level Style Analysis\n",
    "- Assess the dominant strategies in different leagues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style-related columns\n",
    "style_columns = [\n",
    "    'buildUpPlaySpeed', 'buildUpPlayDribbling', 'buildUpPlayPassing', \n",
    "    'chanceCreationPassing', 'chanceCreationCrossing', 'chanceCreationShooting', \n",
    "    'defencePressure', 'defenceAggression', 'defenceTeamWidth'\n",
    "]\n",
    "league_style_analysis = melted_match.groupby(['season','league_name'])[style_columns].mean().reset_index()\n",
    "\n",
    "league_style_analysis.to_csv('league_style_analysis_for_lookerStudio.csv', index_label='Id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the data\n",
    "league_style_melted = league_style_analysis.melt(\n",
    "    id_vars=['season', 'league_name'], \n",
    "    var_name='Style Attribute', \n",
    "    value_name='Average Value'\n",
    ")\n",
    "\n",
    "# Bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=league_style_melted, y='Average Value', x='Style Attribute', hue='league_name', palette='Paired')\n",
    "\n",
    "plt.title('Average Playing Styles Across Leagues', fontsize=16)\n",
    "plt.xlabel('Style Attribute', fontsize=12)\n",
    "plt.ylabel( 'Average Value', fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.legend(title='League', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10) \n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "league_style_analysis = melted_match.groupby('league_name')[style_columns].mean().reset_index()\n",
    "sns.heatmap(league_style_analysis.set_index('league_name'), annot=True, fmt='.2f', cmap='viridis')\n",
    "\n",
    "plt.title('Heatmap of Average Playing Styles by League', fontsize=16)\n",
    "plt.xlabel('Style Attribute', fontsize=12)\n",
    "plt.ylabel('League', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "- Italy Serie A, Scotland Premeir League and England Premier League have higher buildUpPlaySpeed, indicating a faster playing style.\n",
    "- Italy Serie A focuses more on chanceCreationPassing and chanceCreationShooting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight 4: Summary Statistics for players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) Summary statistics for numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['height', 'weight', 'overall_rating', 'potential']\n",
    "summary_stats = player_info[numeric_columns].describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats['median'] = player_info[numeric_columns].median()\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Distribution of the preferred_foot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_distribution = player_info['preferred_foot'].value_counts()\n",
    "\n",
    "# Plot a bar chart\n",
    "sns.barplot(x=foot_distribution.index, y=foot_distribution.values, palette='pastel')\n",
    "plt.title('Distribution of Preferred Foot', fontsize=16)\n",
    "plt.xlabel('Preferred Foot', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) Attacking and Defensive work rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacking_work_rate_dist = player_info['attacking_work_rate'].value_counts()\n",
    "defensive_work_rate_dist = player_info['defensive_work_rate'].value_counts()\n",
    "\n",
    "print(\"Attacking Work Rate Distribution:\")\n",
    "print(attacking_work_rate_dist)\n",
    "\n",
    "print(\"\\nDefensive Work Rate Distribution:\")\n",
    "print(defensive_work_rate_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two distributions for visualization\n",
    "work_rate_data = pd.DataFrame({\n",
    "    'Attacking Work Rate': attacking_work_rate_dist,\n",
    "    'Defensive Work Rate': defensive_work_rate_dist\n",
    "}).T\n",
    "\n",
    "# Create a grouped bar chart\n",
    "work_rate_data.plot(kind='bar', figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "plt.title('Distribution of Work Rates', fontsize=16)\n",
    "plt.xlabel('Work Rate Type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Work Rate Level', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight 5: Tracking trends of the Player Attributes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Players attribute categories\n",
    "\n",
    "Overall_Performance= ['overall_rating', 'potential']\n",
    "\n",
    "Physical_Attributes= ['acceleration', 'sprint_speed', 'agility', 'balance', 'stamina', 'strength', 'jumping']\n",
    "\n",
    "Technical_Skills= ['dribbling', 'ball_control', 'short_passing', 'long_passing', 'crossing', 'finishing', 'heading_accuracy',\n",
    "                   'volleys', 'curve', 'free_kick_accuracy', 'long_shots', 'shot_power']\n",
    "\n",
    "Defensive_Skills= ['interceptions', 'marking', 'standing_tackle', 'sliding_tackle']\n",
    "\n",
    "Mental_Attributes= ['reactions', 'vision', 'positioning', 'aggression']\n",
    "\n",
    "Goalkeeping_Attributes= ['gk_diving', 'gk_handling', 'gk_kicking', 'gk_positioning', 'gk_reflexes']\n",
    "\n",
    "Others= ['preferred_foot', 'attacking_work_rate', 'defensive_work_rate', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important attributes\n",
    "attributes = [\n",
    "    'overall_rating',\n",
    "    'potential',\n",
    "    'acceleration',\n",
    "    'sprint_speed',\n",
    "    'dribbling',\n",
    "    'ball_control',\n",
    "    'short_passing',\n",
    "    'finishing',\n",
    "    'interceptions',\n",
    "    'stamina'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the attributes and group by 'date' \n",
    "trend_data = player_info.groupby('date')[attributes].mean().reset_index()\n",
    "trend_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "for attribute in attributes:\n",
    "    sns.lineplot(data=trend_data, x='date', y=attribute, label=attribute)\n",
    "\n",
    "plt.title('Trend Analysis of Player Attributes Over Time', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Average Value', fontsize=12)\n",
    "plt.legend(title='Attributes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to monthly averages\n",
    "trend_data_monthly = trend_data.set_index('date').resample('M')[attributes].mean().reset_index()\n",
    "trend_data_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the resampled data\n",
    "plt.figure(figsize=(10, 6))\n",
    "for attribute in attributes:\n",
    "    sns.lineplot(data=trend_data_monthly, x='date', y=attribute, label=attribute)\n",
    "\n",
    "plt.title('Monthly Trend Analysis of Player Attributes', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Average Value', fontsize=12)\n",
    "plt.legend(title='Attributes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight 6: Analyzing Player Development over time\n",
    "- Aggregate player's data over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify some players\n",
    "for i in player_info['player_name'].unique():\n",
    "    if 'Henry' in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to track individual player trends grouped by 'date' and 'player_name'\n",
    "player_trends = player_info.groupby(['date', 'player_name'])[attributes].mean().reset_index()\n",
    "player_trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) Lionel Messi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for Lionel Messi\n",
    "messi_data = player_trends[player_trends['player_name'] == 'Lionel Messi']\n",
    "\n",
    "# Melt the data\n",
    "messi_melted = messi_data.melt(id_vars='date', value_vars=attributes, \n",
    "                               var_name='Attribute', value_name='Value')\n",
    "\n",
    "# Plot the line chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=messi_melted, x='date', y='Value', hue='Attribute', marker='o')\n",
    "\n",
    "# Titles and labels\n",
    "plt.title('Player Development for Lionel Messi', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Attribute Value', fontsize=12)\n",
    "plt.ylim(0)\n",
    "\n",
    "\n",
    "plt.legend(title='Attributes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Thierry Henry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for Thierry Henry\n",
    "thierry_data = player_trends[player_trends['player_name'] == 'Thierry Henry']\n",
    "\n",
    "# Melt the data\n",
    "thierry_melted = thierry_data.melt(id_vars='date', value_vars=attributes, \n",
    "                               var_name='Attribute', value_name='Value')\n",
    "\n",
    "# Plot the line chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=thierry_melted, x='date', y='Value', hue='Attribute', marker='o')\n",
    "\n",
    "plt.title('Player Development for Thierry Henry', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Attribute Value', fontsize=12)\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.legend(title='Attributes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) Ronaldinho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for Ronaldinho\n",
    "ronaldinho_data = player_trends[player_trends['player_name'] == 'Ronaldinho']\n",
    "\n",
    "# Melt the data\n",
    "ronaldinho_melted = ronaldinho_data.melt(id_vars='date', value_vars=attributes, \n",
    "                               var_name='Attribute', value_name='Value')\n",
    "\n",
    "# Plot the line chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=ronaldinho_melted, x='date', y='Value', hue='Attribute', marker='o')\n",
    "\n",
    "plt.title('Player Development for Ronaldinho', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Attribute Value', fontsize=12)\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.legend(title='Attributes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (d) Cristiano Ronaldo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for Cristiano Ronaldo\n",
    "cristiano_data = player_trends[player_trends['player_name'] == 'Cristiano Ronaldo']\n",
    "\n",
    "# Melt the data\n",
    "cristiano_melted = cristiano_data.melt(id_vars='date', value_vars=attributes, \n",
    "                               var_name='Attribute', value_name='Value')\n",
    "\n",
    "# Plot the line chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=cristiano_melted, x='date', y='Value', hue='Attribute', marker='o')\n",
    "\n",
    "plt.title('Player Development for Cristiano Ronaldo', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Attribute Value', fontsize=12)\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.legend(title='Attributes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (e) Mikel Arteta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for Mikel Arteta\n",
    "arteta_data = player_trends[player_trends['player_name'] == 'Mikel Arteta']\n",
    "\n",
    "# Melt the data\n",
    "arteta_melted = arteta_data.melt(id_vars='date', value_vars=attributes, \n",
    "                               var_name='Attribute', value_name='Value')\n",
    "\n",
    "# Plot the line chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=arteta_melted, x='date', y='Value', hue='Attribute', marker='o')\n",
    "\n",
    "plt.title('Player Development for Mikel Arteta', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Attribute Value', fontsize=12)\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.legend(title='Attributes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for Mikel Arteta\n",
    "owen_data = player_trends[player_trends['player_name'] == 'Michael Owen']\n",
    "\n",
    "# Melt the data\n",
    "owen_melted = owen_data.melt(id_vars='date', value_vars=attributes, \n",
    "                               var_name='Attribute', value_name='Value')\n",
    "\n",
    "# Plot the line chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=owen_melted, x='date', y='Value', hue='Attribute', marker='o')\n",
    "\n",
    "plt.title('Player Development for Michael Owen', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Attribute Value', fontsize=12)\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.legend(title='Attributes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (-) Comparison betweeen Cristiano Ronaldo and Lionel Messi Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# chart 1 improve\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, position 1\n",
    "sns.lineplot(data=cristiano_melted, x='date', y='Value', hue='Attribute', style='Attribute', marker='o', legend=False)\n",
    "plt.title('Player Development for Cristiano Ronaldo', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Attribute Value', fontsize=12)\n",
    "plt.ylim(0)\n",
    "\n",
    "# chart 2 drop\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, position 2\n",
    "sns.lineplot(data=messi_melted, x='date', y='Value', hue='Attribute', style='Attribute', marker='o')\n",
    "plt.title('Player Development for Lionel Messi', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('')\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.legend(title='Attributes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight 6: Player Age and, Overal Rating and  Potential\n",
    "- Players are at different age in different seasons\n",
    "- We use birthday and date columns to calculate player age and analyze:\n",
    "- (a) Age distribution.\n",
    "- (b) Relationship between age and potential or overall_rating.\n",
    "- (c) Peak performance age for players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'birthday' and 'date' to datetime format\n",
    "player_info['birthday'] = pd.to_datetime(player_info['birthday'])\n",
    "player_info['date'] = pd.to_datetime(player_info['date'])\n",
    "\n",
    "# Calculate ages\n",
    "player_info['age'] = (player_info['date'] - player_info['birthday']).astype('<m8[Y]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) Age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of age column\n",
    "player_info['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "age_dis=player_info.copy()\n",
    "age_dis.drop_duplicates()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot the histogram\n",
    "sns.histplot(age_dis['age'], kde=True, bins=37, color='skyblue')\n",
    "\n",
    "plt.title('Age Distribution of Players', fontsize=16)\n",
    "plt.xlabel('Age', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Relationship Between Age, Potential and Overall Rating\n",
    "- Examine how age relates to potential and overall_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "age_vs_potential_rating = player_info.groupby(['player_api_id', 'age'])[['overall_rating', 'potential']].mean()\n",
    "age_vs_potential_rating  = age_vs_potential_rating .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age vs. Potential\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(data=age_vs_potential_rating , x='age', y='potential', color='orange')\n",
    "plt.title('Age vs Potential', fontsize=16)\n",
    "plt.xlabel('Age', fontsize=12)\n",
    "plt.ylabel('Potential', fontsize=12)\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age vs. Overall Rating\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(data=age_vs_potential_rating , x='age', y='overall_rating', color='green')\n",
    "plt.title('Age vs Overall Rating', fontsize=16)\n",
    "plt.xlabel('Age', fontsize=12)\n",
    "plt.ylabel('Overall Rating', fontsize=12)\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) Peak performance age for players\n",
    "- Identify (a) at what age a player attains Maximum rating (b) the age with the highest average ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the age at which most players reach their maximum rating\n",
    "max_ratings = player_info.groupby(['player_api_id', 'age'])['overall_rating'].max().reset_index().sort_values(by=['player_api_id','overall_rating'], ascending=[True, False])\n",
    "max_ratings.drop_duplicates(subset='player_api_id', inplace=True)\n",
    "\n",
    "# Most common age at peak\n",
    "peak_age = max_ratings['age'].mode()[0]  \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot of age vs. overall rating\n",
    "sns.scatterplot(data=max_ratings, x='age', y='overall_rating', color='green', alpha=0.6, label='Player Ratings')\n",
    "# Add a trend line\n",
    "sns.regplot(data=max_ratings, x='age', y='overall_rating', scatter=False, color='blue', label='Trend Line')\n",
    "\n",
    "# Highlight the most common peak age\n",
    "plt.axvline(peak_age, color='red', linestyle='--', label=f'Peak Age: {int(peak_age)}')\n",
    "\n",
    "plt.title('Age vs Overall Rating with Peak Analysis', fontsize=16)\n",
    "plt.xlabel('Age', fontsize=12)\n",
    "plt.ylabel('Overall Rating', fontsize=12)\n",
    "plt.ylim(0)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(loc='upper left', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating age-group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age bins\n",
    "bins = [0, 15, 18, 21, 24, 27, 30, 33, 36, 39, 41, 44] \n",
    "# Corresponding labels\n",
    "labels = ['Under 15', '15-18', '18-21', '21-24', '24-27', '27-30', '30-33', '33-36', '36-39', '39-41', '41-44']  \n",
    "\n",
    "# Create the age_group column\n",
    "player_info['age_group'] = pd.cut(player_info['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Display a sample to verify\n",
    "player_info[['age', 'age_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by age group and calculate mean and max values\n",
    "age_mean_rating = player_info.groupby('age_group')[['potential', 'overall_rating']].mean().reset_index()\n",
    "age_max_rating = player_info.groupby('age_group')[['potential', 'overall_rating']].max().reset_index()\n",
    "\n",
    "# Identify peak rating ages\n",
    "peak_mean_age = age_mean_rating.loc[age_mean_rating['overall_rating'].idxmax(), 'age_group']\n",
    "peak_max_age = age_max_rating.loc[age_max_rating['overall_rating'].idxmax(), 'age_group']\n",
    "\n",
    "# Plot Age Group vs Ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Mean lines\n",
    "sns.lineplot(data=age_mean_rating, x='age_group', y='potential', label='Mean Potential', color='orange', linewidth=2)\n",
    "sns.lineplot(data=age_mean_rating, x='age_group', y='overall_rating', label='Mean Overall Rating', color='green', linewidth=2)\n",
    "\n",
    "# Max lines\n",
    "sns.lineplot(data=age_max_rating, x='age_group', y='potential', label='Max Potential', color='orange', linestyle='--', linewidth=2)\n",
    "sns.lineplot(data=age_max_rating, x='age_group', y='overall_rating', label='Max Overall Rating', color='green', linestyle='--', linewidth=2)\n",
    "\n",
    "# Highlight peak ages\n",
    "plt.axvline(x=peak_max_age, color='red', linestyle='--', label=f'Peak Max Age: {peak_max_age}')\n",
    "plt.axvline(x=peak_mean_age, color='blue', linestyle='--', label=f'Peak Mean Age: {peak_mean_age}')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Age Group vs Potential and Overall Rating (Mean & Max)', fontsize=16)\n",
    "plt.xlabel('Age Group', fontsize=12)\n",
    "plt.ylabel('Rating', fontsize=12)\n",
    "plt.ylim(0)\n",
    "plt.legend(title='Attributes',  loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform Attribute Clustering using K-Means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features (example)\n",
    "#attributes = Technical_Skills + Physical_Attributes + Defensive_Skills + Mental_Attributes# + Overall_Performance\n",
    "\n",
    "# Important attributes\n",
    "attributes = [\n",
    "    'overall_rating',\n",
    "    'potential',\n",
    "    'acceleration',\n",
    "    'sprint_speed',\n",
    "    'dribbling',\n",
    "    'ball_control',\n",
    "    'short_passing',\n",
    "    'finishing',\n",
    "    'interceptions',\n",
    "    'stamina'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Data to track individual player trends grouped by 'date' and 'player_name'\n",
    "player_attr_cluster = player_info.groupby('player_name')[attributes].mean().reset_index()\n",
    "player_attr_cluster.sort_values(by='player_name')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Subset the data\n",
    "player_attributes = player_attr_cluster[attributes]\n",
    "player_attributes'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Standardize the data (important for clustering)\n",
    "scaler = StandardScaler()\n",
    "scaled_attributes = scaler.fit_transform(player_attributes)\n",
    "scaled_attributes'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Perform K-Means clustering\n",
    "num_clusters = 6\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "player_attr_cluster['cluster'] = kmeans.fit_predict(scaled_attributes)\n",
    "player_attr_cluster'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Check the cluster centers (means of the attributes for each cluster)\n",
    "cluster_centers = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=attributes)\n",
    "cluster_centers.reset_index()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Define the archetypes based on the cluster centers\n",
    "archetypes = {\n",
    "    0: 'Speedy Winger',\n",
    "    1: 'Playmaker',\n",
    "    2: 'All-rounder',\n",
    "    3: 'Defensive Specialist',\n",
    "    4: 'Target Striker',\n",
    "    5: 'Creative Midfielder'\n",
    "}\n",
    "\n",
    "# Map the cluster labels to archetypes\n",
    "cluster_centers['archetype'] = cluster_centers['cluster'].map(archetypes)\n",
    "cluster_centers\n",
    "# Show players with their archetypes\n",
    "#player_attr_cluster[['player_name', 'archetype']].head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes= ['dribbling', 'ball_control', 'short_passing', 'long_passing', 'crossing', 'finishing', 'heading_accuracy',\n",
    "                   'volleys', 'curve', 'free_kick_accuracy', 'long_shots', 'shot_power', 'acceleration', 'sprint_speed', \n",
    "                   'agility', 'balance', 'stamina', 'strength', 'jumping', 'interceptions', 'marking', 'standing_tackle', \n",
    "                   'sliding_tackle', 'reactions', 'vision', 'positioning', 'aggression', 'gk_diving', 'gk_handling', \n",
    "                   'gk_kicking', 'gk_positioning', 'gk_reflexes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_attributes = player_info[attributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the attributes/ Normalize the Data\n",
    "scaler = StandardScaler()\n",
    "normalized_data = scaler.fit_transform(selected_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Players/ Define the number of clusters (e.g., 3 for Speedy Winger, Playmaker, All-rounder)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(normalized_data)\n",
    "\n",
    "# Add the cluster labels to the original dataset\n",
    "player_info['archetype'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean attribute values for each cluster\n",
    "cluster_centers = pd.DataFrame(kmeans.cluster_centers_, columns=attributes)\n",
    "cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Clusters to Archetypes\n",
    "# Create an empty dictionary for cluster-to-archetype mapping\n",
    "archetype_mapping = {}\n",
    "\n",
    "# Iterate through each cluster center and map it to an archetype\n",
    "for cluster_id in cluster_centers.index:\n",
    "    cluster_mean = cluster_centers.loc[cluster_id]\n",
    "\n",
    "    # Define heuristics for mapping clusters to archetypes\n",
    "    if cluster_mean[['gk_diving', 'gk_handling', 'gk_kicking', 'gk_positioning', 'gk_reflexes']].mean() > 70:\n",
    "        archetype_mapping[cluster_id] = 'Goalkeeper'\n",
    "    elif cluster_mean[['sprint_speed', 'crossing', 'marking']].mean() > 65:\n",
    "        archetype_mapping[cluster_id] = 'Full-Back'\n",
    "    elif cluster_mean[['acceleration', 'agility', 'stamina', 'crossing']].mean() > 65:\n",
    "        archetype_mapping[cluster_id] = 'Wing-Back'\n",
    "    elif cluster_mean[['heading_accuracy', 'standing_tackle', 'sliding_tackle']].mean() > 70:\n",
    "        archetype_mapping[cluster_id] = 'Center-Back'\n",
    "    elif cluster_mean[['interceptions', 'marking', 'reactions']].mean() > 65:\n",
    "        archetype_mapping[cluster_id] = 'Sweeper'\n",
    "    elif cluster_mean[['interceptions', 'standing_tackle', 'stamina']].mean() > 65:\n",
    "        archetype_mapping[cluster_id] = 'Defensive Midfielder'\n",
    "    elif cluster_mean[['short_passing', 'long_passing', 'stamina', 'vision']].mean() > 65:\n",
    "        archetype_mapping[cluster_id] = 'Central Midfielder'\n",
    "    elif cluster_mean[['vision', 'positioning', 'short_passing', 'ball_control']].mean() > 70:\n",
    "        archetype_mapping[cluster_id] = 'Attacking Midfielder'\n",
    "    elif cluster_mean[['sprint_speed', 'crossing', 'agility']].mean() > 65:\n",
    "        archetype_mapping[cluster_id] = 'Wide Midfielder (or Winger)'\n",
    "    elif cluster_mean[['finishing', 'heading_accuracy', 'positioning', 'jumping']].mean() > 70:\n",
    "        archetype_mapping[cluster_id] = 'Striker (or Forward)'\n",
    "    elif cluster_mean[['vision', 'short_passing', 'ball_control', 'curve']].mean() > 70:\n",
    "        archetype_mapping[cluster_id] = 'Playmaker'\n",
    "    elif cluster_mean[['strength', 'heading_accuracy', 'finishing', 'jumping']].mean() > 70:\n",
    "        archetype_mapping[cluster_id] = 'Target Striker'\n",
    "    else:\n",
    "        archetype_mapping[cluster_id] = 'All-rounder'  # Default archetype\n",
    "\n",
    "# Map clusters to archetypes in the player_info DataFrame\n",
    "player_info['archetype'] = player_info['cluster_id'].map(archetype_mapping)\n",
    "\n",
    "# Check the mapping results\n",
    "print(player_info[['player_name', 'cluster_id', 'archetype']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Goalkeeper\n",
    "Full-Back\n",
    "Wing-Back\n",
    "Center-Back\n",
    "Sweeper\n",
    "Defensive Midfielder\n",
    "Central Midfielder\n",
    "Attacking Midfielder\n",
    "Wide Midfielder (or Winger)\n",
    "Striker (or Forward)\n",
    "Playmaker\n",
    "Target Striker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `attributes_normalized` is already defined and normalized\n",
    "# and `attributes` contains the names of the attributes used for clustering\n",
    "\n",
    "# Define archetypes\n",
    "archetypes = {\n",
    "    0: 'Speedy Winger',\n",
    "    1: 'Playmaker',\n",
    "    2: 'All-rounder',\n",
    "    3: 'Defensive Specialist',\n",
    "    4: 'Target Striker',\n",
    "    5: 'Creative Midfielder'\n",
    "}\n",
    "\n",
    "# Fit KMeans clustering\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "clusters = kmeans.fit_predict(attributes_normalized)\n",
    "\n",
    "# Add clusters to the dataset\n",
    "player_info['cluster'] = clusters\n",
    "\n",
    "# Calculate mean attribute values for each cluster\n",
    "cluster_centers = pd.DataFrame(kmeans.cluster_centers_, columns=attributes)\n",
    "\n",
    "# Map archetypes to clusters based on cluster center attributes\n",
    "archetype_mapping = {}\n",
    "for cluster_id in cluster_centers.index:\n",
    "    cluster_mean = cluster_centers.loc[cluster_id]\n",
    "    # Example heuristic: choose archetype with max mean value for key defining attributes\n",
    "    if cluster_mean['sprint_speed'] > cluster_mean['short_passing']:\n",
    "        archetype_mapping[cluster_id] = 'Speedy Winger'\n",
    "    elif cluster_mean['short_passing'] > cluster_mean['sprint_speed']:\n",
    "        archetype_mapping[cluster_id] = 'Playmaker'\n",
    "    # Add further rules to refine mapping based on key attributes\n",
    "\n",
    "# Map cluster IDs to archetypes in the player dataset\n",
    "player_info['archetype'] = player_info['cluster'].map(archetype_mapping)\n",
    "\n",
    "# Verify alignment\n",
    "archetype_summary = player_info.groupby('archetype')[attributes].mean()\n",
    "\n",
    "print(\"Cluster Centers:\")\n",
    "print(cluster_centers)\n",
    "print(\"\\nArchetype Summary:\")\n",
    "print(archetype_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For 2D visualization, we can use the first two principal components (PCA) of the scaled data\n",
    "from sklearn.decomposition import PCA'''\n",
    "\n",
    "pca = PCA(n_components=2\n",
    "principal_components = pca.fit_transform(scaled_attributes)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "pca_df['archetype'] = player_info['archetype']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='archetype', palette='Set1', s=100)\n",
    "plt.title('Player Archetypes Based on Skills', fontsize=16)\n",
    "plt.xlabel('Principal Component 1', fontsize=12)\n",
    "plt.ylabel('Principal Component 2', fontsize=12)\n",
    "plt.legend(title='Archetype', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "The soccer database has five datasets, league, country, player, player attribute, team and team attribute. It is a detailed dabase for European major leagues covering several seasons from 2008/2009 t0 2015/2016. \n",
    "\n",
    "The project seeks to answer three questions, what teams improved the most over the time period, which players had the most penalties and which was the the most preferred leg for penalty-takers in 2016 among the players who scored more than the mean penalties in that year?\n",
    "\n",
    "In attempting to find solutions to the question, each dataset was examineed for inconsistencies, colomn names, corrected, missing values replace or droped in certain datasets before they were finally merged and cleaned. Visual presentations created and inteprated.\n",
    "\n",
    "From the analysis and visualization, Richie Lambert is the player who scored most of the penalties. I also found that Paris Saint-Germain is the most improved team over the period of time given, followed by Napoli and Cracovia being the in the third position. Moreover, the findings also indicate that most of the penalty takers in 2016 preferred right leg compared to the right leg. The findings also shows that the distribution of the number of goals scored in the two seasons are right skewed.\n",
    "\n",
    "Whereas I was able to show that there is a correltaion between the number of goals scored in the two extreme seasons (2008/2009 and 2015/2016), theer are  other seasons that were not considered. There is likelihood that a team that improved between the two seasons might not have improved in the seasons prior 2015/2016. Goal difference between the two seasons was used as a measured of improvement in performance because the ultimate objective of team managers, players and teams is to improve to score goals, but there could be criteria for measuring performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from subprocess import call\n",
    "#call(['python', '-m', 'nbconvert', 'Investigate_a_Dataset.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
